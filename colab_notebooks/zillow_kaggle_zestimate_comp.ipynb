{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zillow_kaggle_zestimate_comp.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scfLT2i0MLyD",
        "colab_type": "text"
      },
      "source": [
        "# Environment Sanity Check #\n",
        "\n",
        "Click the _Runtime_ dropdown at the top of the page, then _Change Runtime Type_ and confirm the instance type is _GPU_.\n",
        "\n",
        "Check the output of `!nvidia-smi` to make sure you've been allocated a Tesla T4.\n",
        "\n",
        "#Setup:\n",
        "\n",
        "1. Install most recent Miniconda release compatible with Google Colab's Python install  (3.6.7)\n",
        "2. Install RAPIDS libraries\n",
        "3. Set necessary environment variables\n",
        "4. Copy RAPIDS .so files into current working directory, a workaround for conda/colab interactions\n",
        "- **TLDR**\n",
        "  - Hit `Shift` + `Enter`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-um5d-x7o46",
        "colab_type": "code",
        "outputId": "37bf77fb-7f83-49fc-b5e5-514cd049e32d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "\"\"\"make sure we have the right GPU\n",
        "> column 1 row 3 == Tesla T4\n",
        "\"\"\"\n",
        "# display gpu specs\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Aug 15 03:12:33 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P8    16W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkEdr1VmigyU",
        "colab_type": "text"
      },
      "source": [
        "### Install RAPIDS AI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p129YxxnihcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -nc https://github.com/rapidsai/notebooks-contrib/blob/master/utils/rapids-colab.sh\n",
        "!bash rapids-colab.sh\n",
        "\n",
        "import sys, os\n",
        "\n",
        "sys.path.append('/usr/local/lib/python3.6/site-packages/')\n",
        "os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n",
        "os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CsdVW7SU9Li",
        "colab_type": "text"
      },
      "source": [
        "# Zillow Kaggle Competition RAPIDS Conversion\n",
        "- initially based off eswar3's [Zillow prediction models]( https://github.com/eswar3/Zillow-prediction-models) repo\n",
        "## Download Data\n",
        "- to download the data, please plug in your kaggle api username & key\n",
        "  - you can set up your kaggle api at `https://www.kaggle.com/YOUR USERNAME HERE/account`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1dLRTm168Tk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Info on how to get your api key (kaggle.json) here: https://github.com/Kaggle/kaggle-api#api-credentials\n",
        "!pip install kaggle\n",
        "!mkdir /root/.kaggle\n",
        "# plug api -- get your own API key\n",
        "!echo '{\"username\":\"warobson\",\"key\":\"\"}' > /root/.kaggle/kaggle.json\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "# !kaggle datasets download\n",
        "!kaggle competitions download -c zillow-prize-1\n",
        "\n",
        "# unzip kaggle data\n",
        "!unzip -q \"/content/sample_submission.csv.zip\"\n",
        "!unzip -q \"/content/train_2016_v2.csv.zip\"\n",
        "!unzip -q \"/content/properties_2016.csv.zip\"\n",
        "!unzip -q \"/content/train_2017.csv.zip\"\n",
        "!unzip -q \"/content/properties_2017.csv.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LICr9uz8do9K",
        "colab_type": "text"
      },
      "source": [
        "#### How is the data saved?\n",
        "- inside content directory "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n75DyJ-dm4B",
        "colab_type": "code",
        "outputId": "fbd949ae-aa45-4c67-c6e2-74553239623e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "# display content folder contents\n",
        "!ls \"/content/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9\t\t\t\t  sample_data\n",
            "env-check.py\t\t\t  sample_submission.csv\n",
            "__MACOSX\t\t\t  sample_submission.csv.zip\n",
            "Miniconda3-4.5.4-Linux-x86_64.sh  train_2016_v2.csv\n",
            "properties_2016.csv\t\t  train_2016_v2.csv.zip\n",
            "properties_2016.csv.zip\t\t  train_2017.csv\n",
            "properties_2017.csv\t\t  train_2017.csv.zip\n",
            "properties_2017.csv.zip\t\t  zillow_data_dictionary.xlsx.zip\n",
            "rapids-colab.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lpa1b4edIXuT",
        "colab_type": "text"
      },
      "source": [
        "# Imports\n",
        "### RAPIDS\n",
        "* `cuDf`\n",
        "  - words here\n",
        "* `cuML`\n",
        "  - words here\n",
        "* `cuPy`\n",
        "  - words here\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_Tvf2biLAA9r",
        "colab": {}
      },
      "source": [
        "# rapids imports\n",
        "import cudf, cuml, cupy\n",
        "# general imports \n",
        "import io, requests  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJeywzd2efw7",
        "colab_type": "text"
      },
      "source": [
        "## Data\n",
        "* `properties_2016`\n",
        "  - aprox. 27,000,000 residential properties \n",
        "  - 58 attributes each\n",
        "* `train_2016_v2`\n",
        "  - 90,000 transaction records for closings in the year 2016\n",
        "    * Merge datasets on `property_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uynoUxpx8Xsn",
        "colab_type": "code",
        "outputId": "545d3b69-741a-4f23-86df-62ec7f19fb7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "# import train 2016  data\n",
        "train2016 = cudf.read_csv('/content/train_2016_v2.csv',\n",
        "                          parse_dates=[\"transactiondate\"])\n",
        "# peek display 2016 train\n",
        "print(train2016.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ff87c45bf2d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train2016 = cudf.read_csv('/content/train_2016_v2.csv',\n\u001b[0;32m----> 2\u001b[0;31m                           parse_dates=[\"transactiondate\"])\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# peek display 2016 train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain2016\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: read_csv() got an unexpected keyword argument 'parse_dates'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EfApIzCfEtr",
        "colab_type": "code",
        "outputId": "eabb1351-f4f9-499c-9aea-2fa2953c11a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "# import 2016 properties\n",
        "prop2016 = cudf.read_csv('/content/properties_2016.csv')\n",
        "# peek display 2016 properties\n",
        "print(prop2016.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   parcelid  airconditioningtypeid  architecturalstyletypeid  basementsqft  bathroomcnt  bedroomcnt  buildingclasstypeid ...  censustractandblock\n",
            "0  10754147                                                                         0.0         0.0                      ...                     \n",
            "1  10759547                                                                         0.0         0.0                      ...                     \n",
            "2  10843547                                                                         0.0         0.0                      ...                     \n",
            "3  10859147                                                                         0.0         0.0                  3.0 ...                     \n",
            "4  10879947                                                                         0.0         0.0                  4.0 ...                     \n",
            "[50 more columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGiscxESJDrl",
        "colab_type": "text"
      },
      "source": [
        "## [Zillow Prediction Model](https://github.com/eswar3/Zillow-prediction-models/blob/master/Step%202a-Approach1.ipynb)\n",
        "\n",
        "    In this approach the properties data and transaction data are merged together before adressing any missing values\n",
        "\n",
        "\n",
        "#### Merging Data \n",
        " - we will start by merging the two dataframes\n",
        "  - then rename the new dataframe's attributes to be meaningful \n",
        "    - e.g. from `pooltypeid7` to `pool_with_spa_tub_no` and `structuretaxvaluedollarcnt` to `structure_tax`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4CvSIcwm4B2",
        "colab_type": "code",
        "outputId": "6db5ec53-8522-4483-e2fa-d79d9d9d75e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "# merge 2016 train and property dataframes by parcel id\n",
        "train = train2016.merge(prop2016, how='left', on='parcelid')\n",
        "\n",
        "# work on a copy\n",
        "df_train = train.copy()  # [:int(0.5*len(train))]\n",
        "\n",
        "# add column inidcaticating month of transaction\n",
        "df_train['transaction_month'] = df_train['transactiondate'].dt.month\n",
        "\n",
        "# set colums to be renamed for general english understandability \n",
        "rename_these = {\"bathroomcnt\": \"total_bath\",\n",
        "                \"fullbathcnt\": \"full_bath\",\n",
        "                \"threequarterbathnbr\": \"half_bath\",\n",
        "                \"yardbuildingsqft17\": \"patio_sqft\",\n",
        "                \"yardbuildingsqft26\":\"storage_sqft\",\n",
        "                \"decktypeid\": \"deck_flag\",\n",
        "                \"pooltypeid7\": \"pool_with_spa_tub_no\", \n",
        "                \"pooltypeid2\": \"pool_with_spa_tub_yes\",\n",
        "                \"hashottuborspa\": \"has_hottub_or_spa\", \n",
        "                \"pooltypeid10\": \"just_hottub_or_spa\",\n",
        "                \"calculatedfinishedsquarefeet\":\"total_finished_living_area_sqft\", \n",
        "                \"finishedsquarefeet12\": \"finished_living_area_sqft\",\n",
        "                \"lotsizesquarefeet\": \"lot_area_sqft\",\n",
        "                \"finishedsquarefeet50\":\"finished_living_area_entryfloor_sqft1\",\n",
        "                \"finishedfloor1squarefeet\":\"finished_living_area_entryfloor_sqft2\",\n",
        "                \"finishedsquarefeet6\": \"base_unfinished_and_finished_area_sqft\",\n",
        "                \"finishedsquarefeet15\": \"total_area_sqft\",\n",
        "                \"finishedsquarefeet13\": \"preimeter_living_area_sqft\",\n",
        "                \"taxvaluedollarcnt\":\"total_parcel_tax\",\n",
        "                \"landtaxvaluedollarcnt\":\"land_tax\",\n",
        "                \"taxamount\":\"total_property_tax_2016\",\n",
        "                \"structuretaxvaluedollarcnt\":\"structure_tax\",\n",
        "                \"garagetotalsqft\":\"garage_sqft\",\n",
        "                \"fireplacecnt\":\"fireplace_count\",\n",
        "                \"buildingqualitytypeid \":\"building_quality_id\",\n",
        "                \"heatingorsystemtypeid\":\"heating_system_id\",\n",
        "                \"airconditioningtypeid\":\"ac_id\",\n",
        "                \"storytypeid\": \"basement_flag\",\n",
        "                \"basementsqft\": \"basement_sqft\",\n",
        "                \"poolsizesum\": \"pool_sqft\",\n",
        "                \"poolcnt\": \"pool_count\"}\n",
        "# rename columns \n",
        "df_train = df_train.rename(columns = rename_these)\n",
        "\n",
        "# what's the data frame look like?\n",
        "print(df_train.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   parcelid             logerror         transactiondate  ac_id  architecturalstyletypeid  basement_sqft  total_bath ...  transaction_month\n",
            "0  11827818               0.0402 2016-03-15T00:00:00.000                                                         4.0 ...                  3\n",
            "1  12123024               0.0296 2016-03-15T00:00:00.000                                                         3.0 ...                  3\n",
            "2  13867327               0.0344 2016-03-15T00:00:00.000                                                         2.0 ...                  3\n",
            "3  12681894                0.006 2016-03-15T00:00:00.000                                                         3.0 ...                  3\n",
            "4  12848541  0.06949999999999999 2016-03-15T00:00:00.000    1.0                                                  4.0 ...                  3\n",
            "[53 more columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdtyBI2jFnJv",
        "colab_type": "text"
      },
      "source": [
        "## Conforming Attribute Values\n",
        "### #0 boolean columns & null = 0s cases \n",
        "* `pool_count`, `pool_with_spa_tub_no` and `pool_with_spa_tub_yes` are all binary variables, replace all NULL values with zero\n",
        "*   `basement_flag` has values 7 & `Null` but is supposed to be bool, convert the `7`s to `1`s and the `Null`s to `0`s \n",
        "* patio and shed variables with null values are assumed to have none\n",
        "* deck_flag has only 2 values, `66` and `null`\n",
        "  - convert it into binary flag\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3bPdNONHTYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# replace missing pool count values so we booling\n",
        "the_bool_club = ['pool_count','pool_with_spa_tub_no','pool_with_spa_tub_yes',\n",
        "                 'basement_flag','patio_sqft','storage_sqft', 'deck_flag']\n",
        "for col in the_bool_club:\n",
        "  # convert null values to 0\n",
        "  df_train[col]=df_train[col].fillna(0)\n",
        "# convert 7s and 66s to 1s\n",
        "df_train['basement_flag'] = df_train['basement_flag'].replace(7, 1)\n",
        "df_train['deck_flag'] = df_train['deck_flag'].replace(66, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MbGy6r7JLLD",
        "colab_type": "text"
      },
      "source": [
        "### #1 The pool\n",
        "*   When pool is present and if it has tub/spa then `just_hottub_or_spa` = 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3-1V93smA9A",
        "colab_type": "code",
        "outputId": "66d7335e-bc42-4108-a1c1-80f1afb06a4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "source": [
        "# when poolcnt=1 and has_hottub_or_spa=1 and just_hottub_or_spa is null, then just_hottub_or_spa =0\n",
        "conditions = ((df_train['pool_count'] == 1) \n",
        "              & (df_train['has_hottub_or_spa'] == 1) \n",
        "              & (df_train['just_hottub_or_spa'].isna() == True))\n",
        "df_train['just_hottub_or_spa'] = df_train['just_hottub_or_spa'].masked_assign(0, conditions) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-10369f477b6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m conditions = ((df_train['pool_count'] == 1) \n\u001b[1;32m      2\u001b[0m               \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_hottub_or_spa'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m               & (df_train['just_hottub_or_spa'].isna() == True))\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'just_hottub_or_spa'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'just_hottub_or_spa'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconditions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/site-packages/cudf/dataframe/series.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unordered_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eq'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/site-packages/cudf/dataframe/series.py\u001b[0m in \u001b[0;36m_unordered_compare\u001b[0;34m(self, other, cmpops)\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_unordered_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmpops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0mnvtx_range_push\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CUDF_UNORDERED_COMP\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"orange\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_normalize_binop_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m         \u001b[0moutcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munordered_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmpops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/site-packages/cudf/dataframe/series.py\u001b[0m in \u001b[0;36m_normalize_binop_value\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_binop_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_unordered_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmpops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/site-packages/cudf/dataframe/string.py\u001b[0m in \u001b[0;36mnormalize_binop_value\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cannot broadcast {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdefault_na_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot broadcast <class 'int'>"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6E3-_XlSGBs",
        "colab_type": "text"
      },
      "source": [
        "- when `has_hottub_or_spa` is null and `just_hottub_or_spa` is null\n",
        "  - both should be zero\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa12WFccSGM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if both has hottub and just hottub are null\n",
        "conditions = ((df_train['has_hottub_or_spa'].isna() == True) \n",
        "              & (df_train['just_hottub_or_spa'].isna() == True))\n",
        "# just hottub or spa = 0 \n",
        "df_train['just_hottub_or_spa'] = df_train['just_hottub_or_spa'].masked_assign(0, conditions) \n",
        "\n",
        "# now, if has hottub is null and just hottub is 0 \n",
        "conditions = ((df_train['has_hottub_or_spa'].isna() == True) \n",
        "              & (df_train['just_hottub_or_spa'] == 0))\n",
        "# has hottub or spa = 0 \n",
        "df_train['has_hottub_or_spa'] = df_train['has_hottub_or_spa'].masked_assign(0, conditions) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5umCCWN73qxw",
        "colab_type": "text"
      },
      "source": [
        "- when there is no pool\n",
        "  - if there is tub/spa \n",
        "    - then `just_hottub_or_spa`  = 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBgs7zJm3qk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# when poolcnt=0, has_hottub_or_spa=1\n",
        "conditions = ((df_train['pool_count'] == 0) \n",
        "              & (df_train['has_hottub_or_spa'] == 1))\n",
        "# just_hottub_or_spa=1\n",
        "df_train['just_hottub_or_spa'] = df_train['just_hottub_or_spa'].masked_assign(1, conditions) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LsRr1aoSCVx",
        "colab_type": "text"
      },
      "source": [
        "*   When there is no pool, set pool size to zero instead of na"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtdyXCbx0TKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# where there is no pool\n",
        "conditions = df_train['pool_count']==0\n",
        "# square footage of non existant pool is 0 \n",
        "df_train['pool_sqft'] = df_train['pool_sqft'].masked_assign(0, conditions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hQFkXmAgQPY",
        "colab_type": "text"
      },
      "source": [
        "### #2 The basement\n",
        "*    Where `basement_flag` is zero, `basement_sqft` should also be zero\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMuCOqAmLTmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# where there is no basement\n",
        "conditions = df_train['basement_flag'] == 0\n",
        "# fun fact: we just did this with the pool\n",
        "df_train['basement_sqft'] = df_train['basement_sqft'].masked_assign(0, conditions) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU6Uohb-PDYB",
        "colab_type": "text"
      },
      "source": [
        "### #3 The fireplace\n",
        "There seems to be inconsistency between the `fireplace_flag` and `fireplace_count`\n",
        "- 90,053 flag values are null\n",
        "- 80,688 `fireplace_count` values are null\n",
        "    * 9,385 (-11.5%) difference, but a boatload either way"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZM6lXmmpj5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"there are {df_train['fireplace_count'].isna().sum()} fireplace_count \\\n",
        "nulls\\nthere are {df_train['fireplaceflag'].isna().sum()} fireplaceflag nulls\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9ZAzFoIpkSF",
        "colab_type": "text"
      },
      "source": [
        "* context driven solutions\n",
        "  * where neither flag nor count exists, `fireplaceflag == False`\n",
        "  *   when `fireplace_count` is more than zero `fireplaceflag` should be `True`\n",
        "  * if `fireplaceflag == False`, the `fireplace_count` is logically `0`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3YRZgU_qZhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# null flags with null counts are zero\n",
        "conditions = ((df_train['fireplace_count'].isna()==True) \n",
        "              & (df_train['fireplaceflag'].isna()==True))\n",
        "df_train['fireplaceflag'] = df_train['fireplaceflag'].masked_assign(False, conditions)\n",
        "\n",
        "# true flags for positive fireplace counts\n",
        "conditions = df_train['fireplace_count'] > 0\n",
        "df_train['fireplaceflag'] = df_train['fireplaceflag'].masked_assign(True, conditions)\n",
        "\n",
        "# set fireplace count nulls to 0 where false flags are\n",
        "conditions = ((df_train['fireplace_count'].isna()==True) \n",
        "              & (df_train['fireplaceflag']==False))\n",
        "df_train['fireplace_count'] = df_train['fireplace_count'].masked_assign(0, conditions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pYntUejosOn3"
      },
      "source": [
        "### #4 The garage\n",
        "*   Properties with no garages would have NA values for both "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9mGs-mK9E0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "garage = ['garagecarcnt', 'garage_sqft']\n",
        "# where garage car count and garage square feet are null, set both to 0\n",
        "conditions = ((df_train['garagecarcnt'].isna()==True) \n",
        "              & (df_train['garage_sqft'].isna()==True))\n",
        "for i in garage:\n",
        "  df_train[i] = df_train[i].masked_assign(0, conditions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uV115W6-ohW",
        "colab_type": "text"
      },
      "source": [
        "Exploring the data farther, we see\n",
        "- `garage_sqft` holds over 8,900 measurements of 0 despite the garage's car count being 1 or more  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbbUIbwJ-ouS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show rows where garage count and square feet don't add up\n",
        "conditions = (df_train.garagecarcnt > 0) & (df_train.garage_sqft == 0)\n",
        "print(df_train.loc[conditions][garage])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I1O76QKA8Cb",
        "colab_type": "text"
      },
      "source": [
        "- these 0 values need to be null\n",
        " - because no garage holding 1 or more cars in 2016 measured 0sqft"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWVtoty0A9Jt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# where garage count and square feet don't add up\n",
        "conditions = (df_train.garagecarcnt>0) & (df_train.garage_sqft==0)\n",
        "# insert a NaN value\n",
        "df_train['garage_sqft'] = df_train['garage_sqft'].masked_assign(cupy.nan, conditions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "seb6r5wx5Bbz"
      },
      "source": [
        "### #5 The bath\n",
        "*   `total_bath` & `calculatedbathnbr` are near-duplicates w/ `calculated` having more nulls\n",
        "  - let's drop it\n",
        "*   if `full_bath` is null and `half_bath` is also null\n",
        "  - let's make `total_bath` = 0 \n",
        "      - because we can't truthfully assume it's any more "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EgMNToed5BMu",
        "colab": {}
      },
      "source": [
        "# drop calculated bath column\n",
        "df_train = df_train.drop('calculatedbathnbr', axis=1)\n",
        "\n",
        "# if full_bath is null & half_bath is null\n",
        "conditions = ((df_train['full_bath'].isnull()==True) \n",
        "              & (df_train['half_bath'].isnull()==True))\n",
        "# total_bath=0\n",
        "df_train['total_bath'] = df_train['total_bath'].masked_assign(0, conditions)\n",
        "\n",
        "# when full_bath==total_bath\n",
        "conditions = df_train.full_bath == df_train.total_bath\n",
        "# half_bath=0 \n",
        "df_train['half_bath'] = df_train['half_bath'].masked_assign(0, conditions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Sh8cG0pr4_hl"
      },
      "source": [
        "### #6 Mode Imputation \n",
        "* scaling down the latitude and longitide\n",
        "  - knn imput takes more time due to the larger numbers\n",
        "  - standardizing gives better results on most algorithms\n",
        "    - this is a competition, we came to win"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kitrNxKgLWUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train['latitude'] = [lat/100000 for lat in df_train['latitude']]\n",
        "df_train['longitude'] = [long/100000 for long in df_train['longitude']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6bhRhu5YZ1d",
        "colab_type": "text"
      },
      "source": [
        "### #7 numberofstories & unitcnt & roomcnt\n",
        "* we can devise unit count based on property land type\n",
        "  - so we can now go ahead and correct the unit counts for each given property"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHZH4rMNLfBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# where room count is 0, go ahead and NaN it\n",
        "conditions = df_train['roomcnt'] == 0\n",
        "df_train['roomcnt'] = df_train['roomcnt'].masked_assign(cupy.nan, conditions)\n",
        "\n",
        "\"\"\"\n",
        "propertylandusetypeid & unitcnt are related \n",
        "  these are the propertylandusetypeid codes & their definitions\n",
        "  \n",
        "#246 -Duplex (2 Units, Any Combination)\n",
        "#247 -Triplex (3 Units, Any Combination)\n",
        "#248 -Quadruplex (4 Units, Any Combination)\n",
        "#260 -Residential General\n",
        "#261 -Single Family Residential\n",
        "#263 -Mobile Home\n",
        "#264 -Townhouse\n",
        "#266 -Condominium\n",
        "#267 -Cooperative\n",
        "#269 -Planned Unit Development\n",
        "#275 -Residential Common Area \n",
        "#31 - Commercial/Office/Residential Mixed Used\n",
        "#47 -Store/Office (Mixed Use)\n",
        "#265 -Cluster Home\n",
        "\"\"\"\n",
        "\n",
        "# one unit \n",
        "ones = [260,261,263,264,266,267,269,275]\n",
        "for one in ones:\n",
        "  # adjust conditions to one unit indicator\n",
        "  conditions = ((df_train['propertylandusetypeid'] == one) \n",
        "                & (df_train['unitcnt'].isnull()))\n",
        "  df_train['unitcnt'] = df_train['unitcnt'].masked_assign(1, conditions)\n",
        "\n",
        "# two units \n",
        "twos = [31,47,246]\n",
        "for two in twos:\n",
        "  # adjust conditions to two unit indicator\n",
        "  conditions = ((df_train['propertylandusetypeid'] == two) \n",
        "                & (df_train['unitcnt'].isnull()))\n",
        "  df_train['unitcnt'] = df_train['unitcnt'].masked_assign(2, conditions)\n",
        "\n",
        "# three units\n",
        "conditions = ((df_train['propertylandusetypeid'] == 247) \n",
        "              & (df_train['unitcnt'].isnull()))\n",
        "df_train['unitcnt'] = df_train['unitcnt'].masked_assign(3, conditions)\n",
        "\n",
        "# four units\n",
        "conditions = ((df_train['propertylandusetypeid'] == 248) \n",
        "              & (df_train['unitcnt'].isnull()))\n",
        "df_train['unitcnt'] = df_train['unitcnt'].masked_assign(4, conditions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02yLicmxLs3C",
        "colab_type": "text"
      },
      "source": [
        "### #8 Time to Cut\n",
        "**Because of the adjustments made so far a number of columns are no longer needed**\n",
        "*  transaction date column is no longer of use\n",
        "  - and can be dropped \n",
        "* `preimeter_living_area_sqft` and `total_finished_living_area_sqft` have the same values \n",
        "  - except that `preimeter_living_area_sqft` has more duplicates\n",
        "* `total_area_sqft` and `total_finished_living_area_sqft` have the same values \n",
        "  - except that \"total_area_sqft\" has more duplicates\n",
        "* `total_finished_living_area_sqft` and `finished_living_area_sqft` have the same values \n",
        "  - except that `finished_living_area_sqft` has more duplicates\n",
        "* `base_unfinished_and_finished_area_sqft` and `total_finished_living_area_sqft` have the same values \n",
        "  - except that `base_unfinished_and_finished_area_sqft` has more duplicates\n",
        "* different counties follow different land use code\n",
        "  - to compare different counties, zillow has created it's own `propertylandusetypeid`\n",
        "    - hence we can drop `propertycountylandusecode`\n",
        "    - the same applies to `propertyzoningdesc`\n",
        "* Most zip id's either invalid or out of city\n",
        "  - since enough information about location is given in latitude and longitude \n",
        "    - let's drop other location related fields\n",
        "      - `regionidcity`\n",
        "      - `regionidzip`\n",
        "      - `regionidneighborhood`\n",
        "* `assessmentyear` has a constant value for all rows\n",
        "  - let's drop it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtOgzOqHLyid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# collect columns to drop\n",
        "cut = ['propertyzoningdesc','propertycountylandusecode',\n",
        "       'base_unfinished_and_finished_area_sqft','finished_living_area_sqft',\n",
        "       'total_area_sqft','preimeter_living_area_sqft','regionidzip',\n",
        "       'regionidcity','regionidneighborhood','assessmentyear','transactiondate',\n",
        "       'censustractandblock']\n",
        "# cut columns form dataframe\n",
        "df_train = df_train.drop(cut, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icDvpvSD6BSb",
        "colab_type": "text"
      },
      "source": [
        "### #9 Tax, Year, & Census\n",
        "-  if tax deliquency flag is null, assume there is no unpaid tax on the property\n",
        "  - an issue arrises here because `taxdelinquencyflag` is a `StringColumn`\n",
        "    - i.e. null values indicate no tax delinquency, all other values are `Y` for yes\n",
        "    - because of this, the normal method of.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lYcO_T5XKNN",
        "colab_type": "code",
        "outputId": "0b77457e-0eed-4e21-be79-1df380432abc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "# how we'd normally take care of this\n",
        "df_train['taxdelinquencyflag'].fillna(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-f9b8b7d87fff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'taxdelinquencyflag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/site-packages/cudf/dataframe/series.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, axis, inplace, limit)\u001b[0m\n\u001b[1;32m   1135\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The axis keyword is not supported\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1137\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/site-packages/cudf/dataframe/string.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, fill_value, inplace)\u001b[0m\n\u001b[1;32m    709\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStringColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         ):\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fill_value must be a string or a string series\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0;31m# replace fill_value with nvstrings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: fill_value must be a string or a string series"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA6xG6h59rLi",
        "colab_type": "text"
      },
      "source": [
        "- ...comes with error. \n",
        "  - Why?\n",
        "    - the series we are trying to fill the null values of is a string series\n",
        "      - because of this `.fillna()` requires a sting value (e.g. '0') instead of an int value (e.g. 0)\n",
        "  - So, what now?\n",
        "    - there is an easy and straightforward solution with masked assigning!! \n",
        "      - First\n",
        "        - switch 1 (current True, actual False) to -1\n",
        "      - Then\n",
        "        - switch 0 (current False, actual True) to 1 to reflect True status\n",
        "      - Finally\n",
        "        - switch -1 (old True, actual False) to 0 to reflect False status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Svp6J0cJ5dL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if bool 'Y'/None is already set, change string to int bool column via .isna()\n",
        "df_train['taxdelinquencyflag'] = df_train['taxdelinquencyflag'].isna()\n",
        "\n",
        "# next we must correct the values, with 1 (True) for 'Y' and 0 for no\n",
        "switcharoo = [(1,-1),(0,1),(-1,0)]\n",
        "# switch values in order\n",
        "for pair in switcharoo:\n",
        "  # tag old value and new value it will be replaced with\n",
        "  old, new = pair\n",
        "  # replace old value with new value\n",
        "  df_train['taxdelinquencyflag'] = df_train['taxdelinquencyflag'].replace(old, \n",
        "                                                                          new)\n",
        "# display values in tax delinquency flag column\n",
        "print(df_train['taxdelinquencyflag'].value_counts())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5EAdWXaCTRU",
        "colab_type": "text"
      },
      "source": [
        "- Convert years\n",
        "  - from yy\n",
        "    - to 2016 - yyyy \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Bic66I9LfGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set year paris -- e.g. from 5 to 2016 - 2005\n",
        "year_pairs = [(99,2016-1999),(6,2016-2006),(7,2016-2007),(8,2016-2008),\n",
        "              (9,2016-2009),(10,2016-2010),(11,2016-2011),(12,2016-2012),\n",
        "              (13,2016-2013),(14,2016-2014),(15,2016-2015)]\n",
        "# go though year pairs\n",
        "for pair in year_pairs:\n",
        "  # tag old value and new value it will be replaced with\n",
        "  old, new = pair\n",
        "  # replace old value with new value\n",
        "  df_train['taxdelinquencyyear'] = df_train['taxdelinquencyyear'].replace(old, \n",
        "                                                                          new)\n",
        "# what're we lookin at?\n",
        "print(df_train['taxdelinquencyyear'].value_counts())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ya7xLHzdGVcs",
        "colab_type": "text"
      },
      "source": [
        "- values in `rawcensustractandblock` represent multiple fields concatened together as float values\n",
        "  - by converting those values to string we can split each and build new columns:\n",
        "    - `census_tractnumber`\n",
        "    - `block_number`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3sh8aGovTLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(df_train['rawcensustractandblock'].head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJrFMIuvvqUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using series instead of dataframe\n",
        "tractnumber = s_rawcensustractandblock.values_to_string()\n",
        "# adjust tract number\n",
        "for i in range(len(cudf_tractnumber)):\n",
        "  funct = slice(4,11)\n",
        "  tractnumber[i] = tractnumber[i][funct]\n",
        "# set new tract number column\n",
        "df_train['census_tractnumber'] = census_tractnumber\n",
        "\n",
        "# using series instead of dataframe\n",
        "block_number = s_rawcensustractandblock.values_to_string()\n",
        "# set/adjust block number\n",
        "for i in range(len(block_number)):\n",
        "  funct = slice(11, None)\n",
        "  block_number[i] = block_number[i][funct]\n",
        "  block_number[i] = block_number[i][:4]+'.'+block_number[i][4:]+'0'\n",
        "  block_number[i] = int(round(float(block_number[i]), 0))\n",
        "  block_number[i] = str(block_number[i]).ljust(4,'0')\n",
        "# add block number column to dataframe\n",
        "df_train['block_number'] = block_number\n",
        "\n",
        "# rawcensustractandblock values have been converted\n",
        "df_train = df_train.drop('rawcensustractandblock', axis=1)\n",
        "# let's see what we've got\n",
        "print(df_train[['census_tractnumber', 'block_number']].head(3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T71orw51lpTN",
        "colab_type": "text"
      },
      "source": [
        "## Dealing with Missing Values\n",
        "### #1 Setting standards\n",
        "- Despite corecting and adjusting the data to this point, there are still some columns holding a large majority of null values\n",
        "- For some columns, this majority represents over 95% of values\n",
        "  - Let's identify those columns\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhCosNpXvTVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate null value % for each column & frame it\n",
        "missingvalues_prop = (df_train.isnull().sum()/len(df_train)).reset_index()\n",
        "missingvalues_prop.columns = ['field','percentage']\n",
        "\n",
        "# sort by null values percentage, from highest % to lowest\n",
        "missingvalues_prop = missingvalues_prop.sort_values(by='percentage', \n",
        "                                                    ascending=False)\n",
        "# identify columns with > 95% of values null\n",
        "missingvaluescols = missingvalues_prop.loc[missingvalues_prop['percentage'] > 0.95]\n",
        "\n",
        "# display columns with highest % null values\n",
        "print(missingvaluescols)\n",
        "\n",
        "# drop columns with more than 95% null values\n",
        "df_train = df_train.drop(missingvaluescols['field'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eBIDWEUBHwz",
        "colab_type": "text"
      },
      "source": [
        "- and drop columns with more than 95% null values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az6t2ntBCMRe",
        "colab_type": "text"
      },
      "source": [
        "### #2 Working with Remaining Values\n",
        "- the majority of values still missing in unitcnt are rows were `propertylandusetypeid` = 265, \n",
        "  - which is Cluster Home (i.e. group of houses with shared walls)\n",
        "    - each cluster is anywhere between 5 to 25 units\n",
        "      - here we will asssume 10 units as reassonable count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB2lzAyopS_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# highly related propertylandusetypeid\n",
        "conditions = df_train['propertylandusetypeid'] == 265\n",
        "#  unitcnt            360\n",
        "df_train['unitcnt'] = df_train['unitcnt'].masked_assign(10, conditions)\n",
        "# let's see what we've got\n",
        "print(df_train['unitcnt'].value_counts())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofZIC0EdKJ0Y",
        "colab_type": "text"
      },
      "source": [
        "# -----current: test ready-----"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8Zfn-YhlSBO",
        "colab_type": "code",
        "outputId": "2087fa66-8683-4040-a3e1-7654942367b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "poolsizesum_mean = df_train.loc[df_train['pool_count'] > 0].pool_sqft.mean()\n",
        "\"\"\"\n",
        "NEEDS TO BE CONFIRMED WITH OG\n",
        "> is this supposed to only consider if pool_sqft > 0 as well?\n",
        "\"\"\"\n",
        "poolsizesum_mean"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28.13881906038769"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA30ozCWo5x3",
        "colab_type": "code",
        "outputId": "fda7011f-6bee-4b60-e137-ec04d05e440b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "print(df_train.loc[df_train['pool_count'] > 0].pool_sqft.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5    0.0\n",
            "8    0.0\n",
            "11    0.0\n",
            "13    0.0\n",
            "23    0.0\n",
            "Name: pool_sqft, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-icFDeLSoJwl",
        "colab_type": "code",
        "outputId": "9c5035bd-b766-4509-c5a8-f3a475093dd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 907
        }
      },
      "source": [
        "print(df_train.loc[df_train.pool_count>0].pool_sqft.value_counts())\n",
        "print(df_train.pool_sqft.value_counts())\n",
        "print(df_train.loc[df_train.pool_count>0].pool_sqft.isna().sum())\n",
        "print(df_train.pool_sqft.isna().sum())\n",
        "\n",
        "\n",
        "\n",
        "# calculate the average pool square footage for properties with a pool(s)\n",
        "new_value = df_train.loc[df_train['pool_count'] > 0, 'pool_sqft'].mean()\n",
        "\n",
        "# where the property has a pool(s) but pool square feet is 0\n",
        "conditions = ((df_train['pool_count'] > 0) \n",
        "              & (df_train['pool_sqft'] == 0))\n",
        "\n",
        "# set pool square feet to the average pool square footage of pool properties\n",
        "df_train['pool_sqft'] = df_train['pool_sqft'].masked_assign(new_value, conditions)\n",
        "\n",
        "\n",
        "print(df_train.loc[df_train.pool_count>0].pool_sqft.value_counts())\n",
        "print(df_train.pool_sqft.value_counts())\n",
        "print()\n",
        "print(df_train.loc[df_train.pool_count>0].pool_sqft.isna().sum())\n",
        "print(df_train.pool_sqft.isna().sum())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0    16932\n",
            "450.0      105\n",
            "400.0       41\n",
            "800.0       39\n",
            "500.0       36\n",
            "600.0       35\n",
            "512.0       30\n",
            "480.0       27\n",
            "648.0       18\n",
            "420.0       17\n",
            "[264 more rows]\n",
            "dtype: int64\n",
            "0.0    89306\n",
            "450.0      105\n",
            "400.0       41\n",
            "800.0       39\n",
            "500.0       36\n",
            "600.0       35\n",
            "512.0       30\n",
            "480.0       27\n",
            "648.0       18\n",
            "420.0       17\n",
            "[264 more rows]\n",
            "dtype: int64\n",
            "0\n",
            "0\n",
            "28.13881906038769    16932\n",
            "450.0      105\n",
            "400.0       41\n",
            "800.0       39\n",
            "500.0       36\n",
            "600.0       35\n",
            "512.0       30\n",
            "480.0       27\n",
            "648.0       18\n",
            "420.0       17\n",
            "[264 more rows]\n",
            "dtype: int64\n",
            "0.0    72374\n",
            "28.13881906038769    16932\n",
            "450.0      105\n",
            "400.0       41\n",
            "800.0       39\n",
            "500.0       36\n",
            "600.0       35\n",
            "512.0       30\n",
            "480.0       27\n",
            "648.0       18\n",
            "[265 more rows]\n",
            "dtype: int64\n",
            "\n",
            "0\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pVABkZTYK9F",
        "colab_type": "code",
        "outputId": "42a0b5cc-42e2-41c5-8fdd-11485c45c933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        }
      },
      "source": [
        "# where total tax and land tax are both greater than 0\n",
        "\n",
        "# TESTING (SWITCH TO OG)\n",
        "# test = df_train.copy()\n",
        "# test.loc[(test.total_parcel_tax>0) & (test.land_tax>0),'structure_tax']=test['total_parcel_tax']-test['land_tax']\n",
        "hmm = df_train.loc[(df_train.total_parcel_tax>0) & (df_train.land_tax>0)]\n",
        "print(f'{len(hmm)} rows where total and land are greater than 0')\n",
        "print(f'{len(df_train)} total rows, hopefully the same as above number')\n",
        "print()\n",
        "print(len(hmm.loc[hmm.structure_tax!=hmm['total_parcel_tax']-hmm['land_tax']]))\n",
        "print()\n",
        "print(hmm.loc[hmm.structure_tax!=hmm['total_parcel_tax']-hmm['land_tax']])\n",
        "print()\n",
        "any_neg = hmm.loc[hmm.total_parcel_tax < hmm.land_tax]\n",
        "# if this comes back as 0, setting all structures to total - land should work\n",
        "print(f'{len(any_neg)} total taxes are less than same rows land tax\\n')\n",
        "print(any_neg)\n",
        "# SWITCH TO RAPIDS \n",
        "\"\"\"current concern\n",
        "are there places where total and land are not greater than 0 \n",
        "and setting structure to their difference is not the best move\"\"\"\n",
        "\n",
        "\n",
        "# # structure tax should be equal to total tax minus land tax\n",
        "# df_train['structure_tax'] = df_train['total_parcel_tax'] - df_train['land_tax']\n",
        "new_value = df_train['total_parcel_tax'] - df_train['land_tax']\n",
        "conditions = (df_train.total_parcel_tax>0) & (df_train.land_tax>0)\n",
        "df_train['structure_tax'] = df_train['structure_tax'].masked_assign(new_value, conditions)\n",
        "\n",
        "# # where structure tax is 0\n",
        "conditions = df_train['structure_tax'] == 0\n",
        "# # we do not know the structure tax, so insert a Nan value\n",
        "df_train['structure_tax'] = df_train['structure_tax'].masked_assign(cupy.nan, conditions)\n",
        "\n",
        "# print(test.isna().sum())\n",
        "# print(test.value_counts().head())\n",
        "# print(test_1.isna().sum())\n",
        "# print(test_1.value_counts().head())\n",
        "\n",
        "\n",
        "# SWITCH TO OG \n",
        "\"\"\"\n",
        "#total_parcel_tax\n",
        "#structure_tax\n",
        "#land_tax\n",
        "#total_property_tax_2016\n",
        "#2)recalculate total_parcel_tax =structure_tax + land_tax\n",
        "\n",
        "# total_parcel_tax =structure_tax + land_tax\n",
        "#->structure_tax=total_parcel_tax -land_tax\n",
        "\n",
        "df_train.loc[(df_train.total_parcel_tax>0) & (df_train.land_tax>0),'structure_tax']=df_train['total_parcel_tax']-df_train['land_tax']\n",
        "\n",
        "#structure_tax, i see a lot of structure tax is 0's, those must be NA's\n",
        "\n",
        "df_train.loc[df_train.structure_tax==0,'structure_tax']=np.nan\n",
        "\"\"\"\n",
        "print(df_train.total_property_tax_2016.isnull().sum())\n",
        "print(df_train.structure_tax.isnull().sum())\n",
        "print(df_train.total_parcel_tax.isnull().sum())\n",
        "print(df_train.land_tax.isnull().sum())\n",
        "\n",
        "# SWITCH TO RAPIDS\n",
        "# print(test[['structure_tax','land_tax','total_parcel_tax']])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90274 rows where total and land are greater than 0\n",
            "90275 total rows, hopefully the same as above number\n",
            "\n",
            "379\n",
            "\n",
            "    parcelid               logerror  ac_id  basement_sqft  total_bath  bedroomcnt  buildingqualitytypeid ...  census_tractnumber\n",
            "266  17188959                 0.0944                   0.0         0.0         0.0                        ...             0056.00\n",
            "297  12956410   -0.14850000000000002                   0.0         0.0         0.0                        ...             4080.05\n",
            "336  12966610                 0.0488                   0.0         6.0         9.0                    7.0 ...             4303.01\n",
            "454  17188961                  0.003                   0.0         0.0         0.0                        ...             0056.00\n",
            "474  17188974    0.10260000000000001                   0.0         0.0         0.0                        ...             0056.00\n",
            "555  17266056                -0.5175                   0.0         0.0         0.0                        ...             0059.08\n",
            "601  17205423                 0.0733                   0.0         0.0         0.0                        ...             0076.06\n",
            "790  10858080    0.05450000000000001                   0.0         2.0         3.0                    7.0 ...             1412.01\n",
            "791  10858080    0.08620000000000001                   0.0         2.0         3.0                    7.0 ...             1412.01\n",
            "976  11325190  -0.024300000000000002                   0.0         0.0         0.0                        ...             9102.06\n",
            "[369 more rows]\n",
            "[38 more columns]\n",
            "\n",
            "0 total taxes are less than same rows land tax\n",
            "\n",
            "Empty DataFrame\n",
            "Columns: ['parcelid', 'logerror', 'ac_id', 'basement_sqft', 'total_bath', 'bedroomcnt', 'buildingqualitytypeid', 'census_tractnumber']\n",
            "Index: []\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-bdfcd5900cba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_parcel_tax'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'land_tax'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mconditions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_parcel_tax\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mland_tax\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'structure_tax'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'structure_tax'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconditions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# # where structure tax is 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/site-packages/cudf/dataframe/series.py\u001b[0m in \u001b[0;36mmasked_assign\u001b[0;34m(self, value, mask)\u001b[0m\n\u001b[1;32m   1073\u001b[0m         \"\"\"\n\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1076\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_construct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/site-packages/cudf/dataframe/column.py\u001b[0m in \u001b[0;36mmasked_assign\u001b[0;34m(self, value, mask)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_gpu_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_invert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         )\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnull_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/site-packages/cudf/utils/cudautils.py\u001b[0m in \u001b[0;36mfill_mask\u001b[0;34m(data, mask, value)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mconfigured\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpu_fill_masked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mconfigured\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoJitCUDAKernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36mspecialize\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    761\u001b[0m         '''\n\u001b[1;32m    762\u001b[0m         argtypes = tuple(\n\u001b[0;32m--> 763\u001b[0;31m             [self.typingctx.resolve_argument_type(a) for a in args])\n\u001b[0m\u001b[1;32m    764\u001b[0m         \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    761\u001b[0m         '''\n\u001b[1;32m    762\u001b[0m         argtypes = tuple(\n\u001b[0;32m--> 763\u001b[0;31m             [self.typingctx.resolve_argument_type(a) for a in args])\n\u001b[0m\u001b[1;32m    764\u001b[0m         \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/typing/context.py\u001b[0m in \u001b[0;36mresolve_argument_type\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \"\"\"\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtypeof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPurpose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnumba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/typing/typeof.py\u001b[0m in \u001b[0;36mtypeof\u001b[0;34m(val, purpose)\u001b[0m\n\u001b[1;32m     32\u001b[0m         msg = _termcolor.errmsg(\n\u001b[1;32m     33\u001b[0m             \"cannot determine Numba type of %r\") % (type(val),)\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot determine Numba type of <class 'cudf.dataframe.series.Series'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SID48LOpYvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# regionidcounty is exact copy of fips code, dropping the dulicate column\n",
        "df_train = df_train.drop(['regionidcounty'], axis=1)\n",
        "df_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWmM2J8_pkg1",
        "colab_type": "code",
        "outputId": "2393cbab-218f-4849-c32c-700495dfb18e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "source": [
        "#*******************************\n",
        "#bedroomcnt #1421 zero bed room houses ??, observed it's missing all other room count also missing\n",
        "print(df_train.bedroomcnt.value_counts())\n",
        "\n",
        "conditions = df_train['bedroomcnt'] == 0\n",
        "df_train['bedroomcnt'] = df_train['bedroomcnt'].masked_assign(cupy.nan, conditions)\n",
        "\n",
        "\n",
        "print(df_train.bedroomcnt.value_counts())\n",
        "print(df_train.bedroomcnt.isnull().sum())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.0    35447\n",
            "2.0    22357\n",
            "4.0    20279\n",
            "5.0     5077\n",
            "1.0     3897\n",
            "0.0     1421\n",
            "6.0     1120\n",
            "8.0      274\n",
            "7.0      234\n",
            "9.0       91\n",
            "[7 more rows]\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-29ba50e2a85d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbedroomcnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbedroomcnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/site-packages/cudf/dataframe/series.py\u001b[0m in \u001b[0;36mvalue_counts\u001b[0;34m(self, method, sort)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnull_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m         \u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1830\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/site-packages/cudf/dataframe/numerical.py\u001b[0m in \u001b[0;36mvalue_counts\u001b[0;34m(self, method)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"non sort based value_count() not implemented yet\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0msegs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msortedvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_segments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;31m# Return both values and their counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mout_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcpp_copying\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gather_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msortedvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/site-packages/cudf/dataframe/column.py\u001b[0m in \u001b[0;36m_unique_segments\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0mdensecol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;31m# sort the column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m         \u001b[0msortcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdensecol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_by_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         \u001b[0;31m# find segments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0msortedvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msortcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/site-packages/cudf/dataframe/numerical.py\u001b[0m in \u001b[0;36msort_by_values\u001b[0;34m(self, ascending, na_position)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msort_by_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_position\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"last\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0msort_inds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sorted_inds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0mcol_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcpp_copying\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gather_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_inds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         col_inds = self.replace(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/site-packages/cudf/_sort.py\u001b[0m in \u001b[0;36mget_sorted_inds\u001b[0;34m(by, ascending, na_position)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Must use a boolean or list of booleans\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mcpp_sort\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_order_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_inds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcol_inds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mcudf/bindings/sort.pyx\u001b[0m in \u001b[0;36mcudf.bindings.sort.apply_order_by\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcudf/bindings/sort.pyx\u001b[0m in \u001b[0;36mcudf.bindings.sort.apply_order_by\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: merge_sort: failed to synchronize: an illegal memory access was encountered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qnP2L9LpmeJ",
        "colab_type": "code",
        "outputId": "bc0119de-0644-414f-bf59-bd132c7c0e15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "# propertylandusetypeid & total living area\n",
        "#                              total_bath           1165\n",
        "#                              full_bath           1182\n",
        "#                              half_bath           1182\n",
        "#                                bedroomcnt      1421\n",
        "#                              roomcnt           1416\n",
        "\n",
        "\n",
        "# roomcnt=(full_bath+half_bath)+ bedroomcnt\n",
        "# total_bath=fullbath+ 0.5(half_bath)\n",
        "\n",
        "#caluculate full bath and half bath again from total bath as, it has few extra columns, (fixes 500 missing values in roomcnt )\n",
        "\n",
        "# where full & half bath and bedroom count are not null, but room count is null\n",
        "conditions = ((df_train['full_bath'].isna() == False) \n",
        "              & (df_train['half_bath'].isna() == False) \n",
        "              & (df_train['bedroomcnt'].isna() == False) \n",
        "              & (df_train['roomcnt'].isna() == True))\n",
        "# calculate room count including all full & half baths along with bedroom count\n",
        "new_values = df_train.full_bath + df_train.half_bath + df_train.bedroomcnt\n",
        "df_train['roomcnt'] = df_train['roomcnt'].masked_assign(new_values, conditions)\n",
        "\n",
        "\"\"\"df_train.loc[(df_train.full_bath.notnull()) \n",
        "             & (df_train.half_bath.notnull()) \n",
        "             & (df_train.bedroomcnt.notnull()) \n",
        "             & (df_train.roomcnt.isnull()),['roomcnt']]=df_train.full_bath + df_train.half_bath + df_train.bedroomcnt\"\"\"\n",
        "\n",
        "\n",
        "# most bedroom count and roomcount null are in same place\n",
        "# all column null count 1133 all columns are null\n",
        "\n",
        "print(df_train.total_bath.isnull().sum())\n",
        "print(df_train.full_bath.isnull().sum())\n",
        "print(df_train.half_bath.isnull().sum())\n",
        "print(df_train.bedroomcnt.isnull().sum())\n",
        "print(df_train.roomcnt.isnull().sum())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:Call to cuOccupancyMaxPotentialBlockSize results in UNKNOWN_CUDA_ERROR\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "CudaAPIError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCudaAPIError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-d46f327c0313>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m               \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'half_bath'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m               \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bedroomcnt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m               & (df_train['roomcnt'].isna() == True))\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# calculate room count including all full & half baths along with bedroom count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_bath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf_bath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbedroomcnt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/site-packages/cudf/dataframe/series.py\u001b[0m in \u001b[0;36misna\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \"\"\"Identify missing values in a Series. Alias for isnull.\n\u001b[1;32m   1239\u001b[0m         \"\"\"\n\u001b[0;32m-> 1240\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnotna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/site-packages/cudf/dataframe/series.py\u001b[0m in \u001b[0;36misnull\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1232\u001b[0m             )\n\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudautils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnullmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1235\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/site-packages/cudf/utils/cudautils.py\u001b[0m in \u001b[0;36misnull_mask\u001b[0;34m(data, mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_dary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0mgpu_isnull\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput_dary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0mtpb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_thread_per_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0mtpbm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtpb\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mblkct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mntasks\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtpbm1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mtpb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36m_compute_thread_per_block\u001b[0;34m(self, kernel)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                 \u001b[0;31m# Raises from the driver if the feature is unavailable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_max_potential_block_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0;31m# Fallback to table-based approach.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36mget_max_potential_block_size\u001b[0;34m(self, func, b2d_func, memsize, blocksizelimit, flags)\u001b[0m\n\u001b[1;32m    646\u001b[0m                                                     \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m                                                     \u001b[0mb2d_cb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m                                                     memsize, blocksizelimit)\n\u001b[0m\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             driver.cuOccupancyMaxPotentialBlockSizeWithFlags(byref(gridsize), byref(blocksize),\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36msafe_cuda_api_call\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'call driver api: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msafe_cuda_api_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36m_check_error\u001b[0;34m(self, fname, retcode)\u001b[0m\n\u001b[1;32m    323\u001b[0m                     \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_getpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCudaDriverError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CUDA initialized before forking\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCudaAPIError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCudaAPIError\u001b[0m: [700] Call to cuOccupancyMaxPotentialBlockSize results in UNKNOWN_CUDA_ERROR"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mvy51Ckev9CX",
        "colab_type": "text"
      },
      "source": [
        "- correct number of stories by Zillow's `propertylandusetypeid` indicator\n",
        "  - where null values are not\n",
        "    - number of stories can be set to mode\n",
        "  - where there are null values\n",
        "    - number of stories can be set to the generally accepted number of stories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW4CG2InpolD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# before\n",
        "print(df_train.numberofstories.isnull().sum())\n",
        "print(df_train.numberofstories.value_counts())\n",
        "\n",
        "#numberofstories\t69705\n",
        "\n",
        "# store ids and general number of stories \n",
        "zillow_type_ids = [(31,2), (246,2), (247,2), (248,2), (260,2), (261,1), \n",
        "                   (263,1), (266,1), (267,1), (269, 2), (275,1)]\n",
        "\n",
        "# go through each id pair \n",
        "for type_id in zillow_type_ids:\n",
        "  # split the pair into type id and number of stories\n",
        "  id, n_stories = type_id\n",
        "\n",
        "  # when type id matches and story count is not null\n",
        "  conditions = ((df_train['propertylandusetypeid'] == id) \n",
        "                & (df_train['numberofstories'].isna() == False))\n",
        "  # calculate the mode story count for matching id properties\n",
        "  mode_stories = df_train.loc[conditions, 'numberofstories'].mode()\n",
        "  # and set those non null values to the most common value seen\n",
        "  df_train['numberofstories'] = df_train['numberofstories'].masked_assign(mode_stories, \n",
        "                                                                          conditions)\n",
        "  \n",
        "  # when type id matches and story count is null\n",
        "  conditions = ((df_train['propertylandusetypeid'] == id) \n",
        "                & (df_train['numberofstories'].isna() == False))\n",
        "  # set null values to the common number of stories seen in that type id\n",
        "  df_train['numberofstories'] = df_train['numberofstories'].masked_assign(n_stories, \n",
        "                                                                          conditions)\n",
        "  \n",
        "# TO BE ADDRESSED\n",
        "# #https://en.wikipedia.org/wiki/Townhouse , typical town house are usually large, and has atleast 6 rooms\n",
        "# df_train.loc[(df_train.propertylandusetypeid==264) & (df_train.numberofstories.isnull()),'numberofstories']=2\n",
        "\n",
        "\"\"\"\n",
        "df_train.loc[(df_train.propertylandusetypeid==246) & (df_train.numberofstories.notnull()),'numberofstories'].mode()\n",
        "df_train.loc[(df_train.propertylandusetypeid==246) & (df_train.numberofstories.isnull()),'numberofstories']=2\n",
        "\n",
        "df_train.loc[(df_train.propertylandusetypeid==247) & (df_train.numberofstories.notnull()),'numberofstories'].mode()\n",
        "df_train.loc[(df_train.propertylandusetypeid==247) & (df_train.numberofstories.isnull()),'numberofstories']=2\n",
        "\n",
        "df_train.loc[(df_train.propertylandusetypeid==248) & (df_train.numberofstories.notnull()),'numberofstories'].mode()\n",
        "df_train.loc[(df_train.propertylandusetypeid==248) & (df_train.numberofstories.isnull()),'numberofstories']=2\n",
        "\n",
        "df_train.loc[(df_train.propertylandusetypeid==260) & (df_train.numberofstories.notnull()),'numberofstories'].mode()\n",
        "df_train.loc[(df_train.propertylandusetypeid==260) & (df_train.numberofstories.isnull()),'numberofstories']=2\n",
        "\n",
        "df_train.loc[(df_train.propertylandusetypeid==261) & (df_train.numberofstories.notnull()),'numberofstories'].mode()\n",
        "df_train.loc[(df_train.propertylandusetypeid==261) & (df_train.numberofstories.isnull()),'numberofstories']=1\n",
        "\n",
        "df_train.loc[(df_train.propertylandusetypeid==263) & (df_train.numberofstories.notnull()),'numberofstories'].mode()\n",
        "df_train.loc[(df_train.propertylandusetypeid==263) & (df_train.numberofstories.isnull()),'numberofstories']=1\n",
        "\n",
        "df_train.loc[(df_train.propertylandusetypeid==266) & (df_train.numberofstories.notnull()),'numberofstories'].mode()\n",
        "df_train.loc[(df_train.propertylandusetypeid==266) & (df_train.numberofstories.isnull()),'numberofstories']=1\n",
        "\n",
        "df_train.loc[(df_train.propertylandusetypeid==269) & (df_train.numberofstories.notnull()),'numberofstories'].mode()\n",
        "df_train.loc[(df_train.propertylandusetypeid==269) & (df_train.numberofstories.isnull()),'numberofstories']=2\n",
        "\n",
        "prop2016.loc[(prop2016.propertylandusetypeid==275) & (prop2016.numberofstories.notnull()),'numberofstories'].mode()\n",
        "df_train.loc[(df_train.propertylandusetypeid==275) & (df_train.numberofstories.isnull()),'numberofstories']=1\n",
        "\n",
        "prop2016.loc[(prop2016.propertylandusetypeid==267) & (prop2016.numberofstories.notnull()),'numberofstories'].mode()\n",
        "df_train.loc[(df_train.propertylandusetypeid==267) & (df_train.numberofstories.isnull()),'numberofstories']=1\n",
        "\n",
        "#https://en.wikipedia.org/wiki/Townhouse , typical town house are usually large, and has atleast 6 rooms\n",
        "df_train.loc[(df_train.propertylandusetypeid==264) & (df_train.numberofstories.isnull()),'numberofstories']=2\n",
        "\n",
        "prop2016.loc[(prop2016.propertylandusetypeid==31) & (prop2016.numberofstories.notnull()),'numberofstories'].mode()\n",
        "df_train.loc[(df_train.propertylandusetypeid==31) & (df_train.numberofstories.isnull()),'numberofstories']=2\"\"\"\n",
        "\n",
        "# after\n",
        "print(df_train.numberofstories.isnull().sum())\n",
        "print(df_train.numberofstories.value_counts())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHcMsDCxprd4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"skeptical of this0 cell (and the one above)..\n",
        "author provides no explination for moding\"\"\"\n",
        "\n",
        "# before\n",
        "print(df_train.fireplace_count.isnull().sum())\n",
        "print(df_train.fireplace_count.value_counts())\n",
        "\n",
        "# where there is a fire place, and count is not null\n",
        "conditions = ((df_train.fireplaceflag==1) \n",
        "              & (df_train.fireplace_count.isna() == False))\n",
        "# calculate the mode fireplace count \n",
        "mode_fire_count = df_train.loc[conditions, 'fireplace_count'].mode()\n",
        "# and set those non null values to the most common fireplace count\n",
        "df_train['fireplace_count'] = df_train['fireplace_count'].masked_assign(mode_fire_count, \n",
        "                                                                        conditions)\n",
        "\n",
        "# where there is a fire place, and count is null\n",
        "conditions = ((df_train.fireplaceflag==1) \n",
        "              & (df_train.fireplace_count.isna() == True))\n",
        "# set null values to the most common fireplace count\n",
        "df_train['fireplace_count'] = df_train['fireplace_count'].masked_assign(1, \n",
        "                                                                        conditions)\n",
        "\n",
        "# df_train.loc[(df_train.fireplaceflag==1) & (df_train.fireplace_count.notnull()),'fireplace_count'].mode()\n",
        "# df_train.loc[(df_train.fireplaceflag==1) & (df_train.fireplace_count.isnull()),'fireplace_count']=1\n",
        "\n",
        "# after\n",
        "print(df_train.fireplace_count.isnull().sum())\n",
        "print(df_train.fireplace_count.value_counts())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVgF1c_p_bN1",
        "colab_type": "text"
      },
      "source": [
        "# -----current: break-----"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIuSWoJspt3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "color = sns.color_palette()\n",
        "sns.set(style=\"darkgrid\")\n",
        "\n",
        "\n",
        "ax = sns.countplot(x=\"buildingqualitytypeid\", data=df_train)\n",
        "\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.title(\"Frequency of Bathroom count\", fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOHPCFRSp5y9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(df_train.yearbuilt,df_train.buildingqualitytypeid , 'ro')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_647tI5Lp94v",
        "colab_type": "text"
      },
      "source": [
        "### Final adjustments\n",
        "- filling nans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4A3-sjRp8AE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#location seems to be related to building quality, (knnclassifier)\n",
        "\n",
        "def fillna_knn( df, base, target):\n",
        "    data_colnames = [ target ] + base\n",
        "    #print(\"data_colnames\",data_colnames)\n",
        "    missing_values_boolflag = df[target].isnull() #true for missing rows, false for columns with values\n",
        "    #print(\"miss\",missing_values_boolflag.head())\n",
        "    not_missing_boolflag = ~missing_values_boolflag \n",
        "    #print(\"not miss\",not_missing_boolflag.head())\n",
        "    number_of_missing_val = missing_values_boolflag.sum()\n",
        "    print(\"# of miss\",number_of_missing_val)\n",
        "    not_missing_rows = df.loc[ not_missing_boolflag, data_colnames ]\n",
        "    #print(not_missing_rows.head())\n",
        "    Y = not_missing_rows[target]\n",
        "    X = not_missing_rows[base]\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=3192,stratify=Y)\n",
        "    metrics       = ['euclidean'] \n",
        "    weights       = ['distance'] \n",
        "    numNeighbors  = [5,10,15,20,25]\n",
        "    param_grid    = dict(metric=metrics,weights=weights,n_neighbors=numNeighbors)\n",
        "    cv            = StratifiedKFold(n_splits=3,random_state=3192,shuffle=False)\n",
        "    grid = GridSearchCV(neighbors.KNeighborsClassifier(n_jobs=-1),param_grid=param_grid,cv=cv,scoring='f1_weighted',refit=True,return_train_score=True,verbose=1,n_jobs=-1,pre_dispatch='n_jobs')\n",
        "    grid.fit(X_train ,Y_train)\n",
        "    #print(\"grid.cv_results_\",grid.cv_results_)\n",
        "    print(\"grid.best_estimator_\",grid.best_estimator_)\n",
        "    print(\"grid.best_params_\",grid.best_params_)\n",
        "    print(\"grid.scorer_\",grid.scorer_)\n",
        "    #print(\"grid.n_splits_\",grid.n_splits_)\n",
        "    y_true, y_pred = Y_test, grid.predict(X_test)\n",
        "    \n",
        "    Z = grid.predict(df.loc[missing_values_boolflag, base])\n",
        "    #df.loc[ missing_values_boolflag, target ]  = Z\n",
        "    return Z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCyRxp-7qEXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(df_train.buildingqualitytypeid.isnull().sum())\n",
        "print(df_train.shape)\n",
        "temp=df_train.copy()\n",
        "temp['buildingqualitytypeid']=temp['buildingqualitytypeid'].fillna(-1)\n",
        "temp=temp.groupby(\"buildingqualitytypeid\").filter(lambda x: x.buildingqualitytypeid.size > 3)\n",
        "temp['buildingqualitytypeid'] = temp['buildingqualitytypeid'].replace(-1,np.nan)\n",
        "print(temp.buildingqualitytypeid.isnull().sum())\n",
        "print(temp.shape)\n",
        "\n",
        "missing_values=fillna_knn(temp,\n",
        "                  base = [ 'latitude', 'longitude' ] ,\n",
        "                  target = 'buildingqualitytypeid')\n",
        "\n",
        "print(\"predicted output shape\",missing_values.shape)\n",
        "missing_values_boolflag = df_train['buildingqualitytypeid'].isnull()\n",
        "df_train.loc[ missing_values_boolflag, 'buildingqualitytypeid' ]  = missing_values\n",
        "\n",
        "print(df_train.buildingqualitytypeid.isnull().sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTh_XPErqkHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(df_train.heating_system_id.isnull().sum())\n",
        "print(df_train.shape)\n",
        "temp=df_train.copy()\n",
        "temp['heating_system_id']=temp['heating_system_id'].fillna(-1)\n",
        "temp=temp.groupby(\"heating_system_id\").filter(lambda x: x.heating_system_id.size > 3)\n",
        "temp['heating_system_id'] = temp['heating_system_id'].replace(-1,np.nan)\n",
        "print(temp.heating_system_id.isnull().sum())\n",
        "print(temp.shape)\n",
        "\n",
        "missing_values=fillna_knn(temp,\n",
        "                  base = [ 'latitude', 'longitude' ] ,\n",
        "                  target = 'heating_system_id')\n",
        "\n",
        "print(\"predicted output shape\",missing_values.shape)\n",
        "missing_values_boolflag = df_train['heating_system_id'].isnull()\n",
        "df_train.loc[ missing_values_boolflag, 'heating_system_id' ]  = missing_values\n",
        "\n",
        "\n",
        "print(df_train.heating_system_id.isnull().sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVjNSkUYqnCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(df_train.ac_id.isnull().sum())\n",
        "print(df_train.shape)\n",
        "temp=df_train.copy()\n",
        "temp['ac_id']=temp['ac_id'].fillna(-1)\n",
        "temp=temp.groupby(\"ac_id\").filter(lambda x: x.ac_id.size > 3)\n",
        "temp['ac_id'] = temp['ac_id'].replace(-1,np.nan)\n",
        "print(temp.ac_id.isnull().sum())\n",
        "print(temp.shape)\n",
        "\n",
        "missing_values=fillna_knn(temp,\n",
        "                  base = [ 'latitude', 'longitude' ] ,\n",
        "                  target = 'ac_id')\n",
        "\n",
        "print(\"predicted output shape\",missing_values.shape)\n",
        "missing_values_boolflag = df_train['ac_id'].isnull()\n",
        "df_train.loc[ missing_values_boolflag, 'ac_id' ]  = missing_values\n",
        "\n",
        "print(df_train.ac_id.isnull().sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTbcYbexqr0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#yearbuilt\n",
        "print(df_train.yearbuilt.isnull().sum())\n",
        "print(df_train.shape)\n",
        "temp=df_train.copy()\n",
        "temp['yearbuilt']=temp['yearbuilt'].fillna(-1)\n",
        "temp=temp.groupby(\"yearbuilt\").filter(lambda x: x.yearbuilt.size > 3)\n",
        "temp['yearbuilt'] = temp['yearbuilt'].replace(-1,np.nan)\n",
        "print(temp.yearbuilt.isnull().sum())\n",
        "print(temp.shape)\n",
        "\n",
        "missing_values=fillna_knn(temp,\n",
        "                  base = [ 'latitude', 'longitude','buildingqualitytypeid','propertylandusetypeid' ] ,\n",
        "                  target = 'yearbuilt')\n",
        "\n",
        "print(\"predicted output shape\",missing_values.shape)\n",
        "missing_values_boolflag = df_train['yearbuilt'].isnull()\n",
        "df_train.loc[ missing_values_boolflag, 'yearbuilt' ]  = missing_values\n",
        "print(df_train.yearbuilt.isnull().sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx1LYGmfqxLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#location seems to be related to building quality, (knnregressor)\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def fillna_knnr( df, base, target):\n",
        "    data_colnames = [ target ] + base\n",
        "    #print(\"data_colnames\",data_colnames)\n",
        "    missing_values_boolflag = df[target].isnull() #true for missing rows, false for columns with values\n",
        "    #print(\"miss\",missing_values_boolflag.head())\n",
        "    not_missing_boolflag = ~missing_values_boolflag \n",
        "    #print(\"not miss\",not_missing_boolflag.head())\n",
        "    number_of_missing_val = missing_values_boolflag.sum()\n",
        "    print(\"# of miss\",number_of_missing_val)\n",
        "    not_missing_rows = df.loc[ not_missing_boolflag, data_colnames]\n",
        "    #print(not_missing_rows.head())\n",
        "    Y = not_missing_rows[target]\n",
        "    X = not_missing_rows[base]\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=3192)\n",
        "    metrics       = ['euclidean'] \n",
        "    weights       = ['distance'] \n",
        "    numNeighbors  = [5,10,15,20,25]\n",
        "    param_grid    = dict(metric=metrics,weights=weights,n_neighbors=numNeighbors)\n",
        "    cv            = KFold(n_splits=3,random_state=3192,shuffle=False) \n",
        "    grid = GridSearchCV(neighbors.KNeighborsRegressor(n_jobs=-1),param_grid=param_grid,cv=cv,scoring='neg_mean_absolute_error',refit=True,return_train_score=True,verbose=1,n_jobs=-1,pre_dispatch='n_jobs')\n",
        "    grid.fit(X_train ,Y_train)\n",
        "    #print(\"grid.cv_results_\",grid.cv_results_)\n",
        "    print(\"grid.best_estimator_\",grid.best_estimator_)\n",
        "    print(\"grid.best_params_\",grid.best_params_)\n",
        "    print(\"grid.scorer_\",grid.scorer_)\n",
        "    #print(\"grid.n_splits_\",grid.n_splits_)\n",
        "    y_true, y_pred = Y_test, grid.predict(X_test) \n",
        "    Z = grid.predict(df.loc[missing_values_boolflag, base])\n",
        "    #df.loc[ missing_values_boolflag, target ]  = Z\n",
        "    return Z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj5PXm7ozg5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#garage_sqft\n",
        "print(df_train.garage_sqft.isnull().sum())\n",
        "print(df_train.shape)\n",
        "temp=df_train.loc[df_train.garagecarcnt>0,df_train.columns].copy()\n",
        "\n",
        "print(temp.garage_sqft.isnull().sum())\n",
        "print(temp.shape)\n",
        "\n",
        "missing_values=fillna_knnr(temp,\n",
        "                  base = [ 'latitude', 'longitude','garagecarcnt'] ,\n",
        "                  target = 'garage_sqft')\n",
        "\n",
        "print(\"predicted output shape\",missing_values.shape)\n",
        "missing_values_boolflag = df_train['garage_sqft'].isnull()\n",
        "df_train.loc[ missing_values_boolflag, 'garage_sqft' ] = missing_values\n",
        "print(df_train.garage_sqft.isnull().sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7e5CFTyzg_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = df_train.drop('parcelid', axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxGquCOOzhD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#All the other columns with missing values seems to be  integer, will need regression to be imputed,\n",
        "#time to get categorical variables hot encoded\n",
        "\n",
        "#Identify numerical columns to produce a heatmap\n",
        "catcols = ['ac_id','buildingqualitytypeid','deck_flag','fips', 'heating_system_id','has_hottub_or_spa',\n",
        "          'just_hottub_or_spa', 'pool_with_spa_tub_yes','pool_with_spa_tub_no','propertylandusetypeid','basement_flag'\n",
        "          ,'fireplaceflag','taxdelinquencyflag']\n",
        "numcols = [x for x in df_train.columns if x not in catcols]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVZkszJEzhHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#total_finished_living_area_sqft\n",
        "\n",
        "print(df_train.total_finished_living_area_sqft.isnull().sum())\n",
        "print(df_train.shape)\n",
        "temp=df_train.copy()\n",
        "print(temp.total_finished_living_area_sqft.isnull().sum())\n",
        "print(temp.shape)\n",
        "missing_values=fillna_knnr(temp,\n",
        "                  base = [ 'latitude', 'longitude','basementsqft','numberofstories','poolcnt','garagecarcnt','garage_sqft','propertylandusetypeid'] ,\n",
        "                  target = 'total_finished_living_area_sqft')\n",
        "\n",
        "print(\"predicted output shape\",missing_values.shape)\n",
        "missing_values_boolflag = df_train['total_finished_living_area_sqft'].isnull()\n",
        "df_train.loc[ missing_values_boolflag, 'total_finished_living_area_sqft' ] = missing_values\n",
        "print(df_train.total_finished_living_area_sqft.isnull().sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVrTMb92zhLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#total_bath\t1165\n",
        "#full_bath\t1182\n",
        "#half_bath\t1182\n",
        "#roomcnt\t1416\n",
        "#bedroomcnt\t1421\n",
        "\n",
        "#total_finished_living_area_sqft\n",
        "\n",
        "print(df_train.total_bath.isnull().sum())\n",
        "print(df_train.shape)\n",
        "temp=df_train.copy()\n",
        "print(temp.total_bath.isnull().sum())\n",
        "print(temp.shape)\n",
        "missing_values=fillna_knnr(temp,\n",
        "                  base = ['propertylandusetypeid','total_finished_living_area_sqft' ] ,\n",
        "                  target = 'total_bath')\n",
        "\n",
        "print(\"predicted output shape\",missing_values.shape)\n",
        "missing_values_boolflag = df_train['total_bath'].isnull()\n",
        "df_train.loc[ missing_values_boolflag, 'total_bath' ] = missing_values\n",
        "print(df_train.total_bath.isnull().sum())#total_bath\t1165\n",
        "#full_bath\t1182\n",
        "#half_bath\t1182\n",
        "#roomcnt\t1416\n",
        "#bedroomcnt\t1421\n",
        "\n",
        "#total_finished_living_area_sqft\n",
        "\n",
        "print(df_train.total_bath.isnull().sum())\n",
        "print(df_train.shape)\n",
        "temp=df_train.copy()\n",
        "print(temp.total_bath.isnull().sum())\n",
        "print(temp.shape)\n",
        "missing_values=fillna_knnr(temp,\n",
        "                  base = ['propertylandusetypeid','total_finished_living_area_sqft' ] ,\n",
        "                  target = 'total_bath')\n",
        "\n",
        "print(\"predicted output shape\",missing_values.shape)\n",
        "missing_values_boolflag = df_train['total_bath'].isnull()\n",
        "df_train.loc[ missing_values_boolflag, 'total_bath' ] = missing_values\n",
        "print(df_train.total_bath.isnull().sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjIKlu-tzhPI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rop half_bath and full bath, as there are only redundant values of total_bath\n",
        "df_train = df_train.drop(['full_bath','half_bath'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02X1y6EBzhT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#bedroomcnt\t1421\n",
        "\n",
        "print(df_train.bedroomcnt.isnull().sum())\n",
        "print(df_train.shape)\n",
        "temp=df_train.copy()\n",
        "print(temp.bedroomcnt.isnull().sum())\n",
        "print(temp.shape)\n",
        "missing_values=fillna_knnr(temp,\n",
        "                  base = ['propertylandusetypeid','total_finished_living_area_sqft','total_bath' ] ,\n",
        "                  target = 'bedroomcnt')\n",
        "\n",
        "print(\"predicted output shape\",missing_values.shape)\n",
        "missing_values_boolflag = df_train['bedroomcnt'].isnull()\n",
        "df_train.loc[ missing_values_boolflag, 'bedroomcnt' ] = missing_values\n",
        "print(df_train.bedroomcnt.isnull().sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzkZ_qeHzhXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train['total_bath']=df_train.total_bath.round(1)\n",
        "df_train['bedroomcnt']=df_train.bedroomcnt.round(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF9DtDAczhaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#recalculate roomcnt\t1416 as we have used imputation for total_bath and bedroomcnt\n",
        "\n",
        "df_train.loc[(df_train.roomcnt.isnull()),['roomcnt']]=df_train.total_bath + df_train.bedroomcnt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5N41TBlz60W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(df_train.shape)\n",
        "df_train =df_train.loc[(df_train.total_parcel_tax.notnull()) & (df_train.land_tax.notnull()),df_train.columns]\n",
        "\n",
        "print(df_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv9h5yL3z64Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#lot_area_sqft\n",
        "print(df_train.lot_area_sqft.isnull().sum())\n",
        "print(df_train.shape)\n",
        "temp=df_train.copy()\n",
        "print(temp.lot_area_sqft.isnull().sum())\n",
        "print(temp.shape)\n",
        "missing_values=fillna_knnr(temp,\n",
        "                  base = ['latitude','longitude','propertylandusetypeid','total_finished_living_area_sqft','roomcnt','numberofstories' ] ,\n",
        "                  target = 'lot_area_sqft')\n",
        "\n",
        "print(\"predicted output shape\",missing_values.shape)\n",
        "missing_values_boolflag = df_train['lot_area_sqft'].isnull()\n",
        "df_train.loc[ missing_values_boolflag, 'lot_area_sqft' ] = missing_values.round(2)\n",
        "print(df_train.lot_area_sqft.isnull().sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYJLHrR4z68f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict structure_tax and recalculate  total_parcel_tax = land_tax + structure_tax\n",
        "\n",
        "\n",
        "print(df_train.structure_tax.isnull().sum())\n",
        "print(df_train.shape)\n",
        "temp=df_train.copy()\n",
        "print(temp.structure_tax.isnull().sum())\n",
        "print(temp.shape)\n",
        "missing_values=fillna_knnr(temp,\n",
        "                  base = ['latitude','longitude','lot_area_sqft','propertylandusetypeid','total_finished_living_area_sqft','roomcnt','numberofstories' ] ,\n",
        "                  target = 'structure_tax')\n",
        "\n",
        "print(\"predicted output shape\",missing_values.shape)\n",
        "missing_values_boolflag = df_train['structure_tax'].isnull()\n",
        "df_train.loc[ missing_values_boolflag, 'structure_tax' ] = missing_values.round(2)\n",
        "print(df_train.structure_tax.isnull().sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya-3K06Zz6_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#36 total_property_tax_2016 \n",
        "\n",
        "#total_parcel_tax = land_tax + structure_tax\n",
        "    \n",
        "df_train['total_parcel_tax']=df_train['structure_tax']+df_train['land_tax']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Fvr7voVz7DX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#age of the property\n",
        "df_train['age'] = 2016 - df_train['yearbuilt']\n",
        "df_train=df_train.drop(['yearbuilt'],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl0EOIT-z7Gl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#total_property_tax_2016\n",
        "\n",
        "\n",
        "print(df_train.total_property_tax_2016.isnull().sum())\n",
        "print(df_train.shape)\n",
        "temp=df_train.copy()\n",
        "print(temp.total_property_tax_2016.isnull().sum())\n",
        "print(temp.shape)\n",
        "missing_values=fillna_knnr(temp,\n",
        "                  base = ['latitude','longitude','lot_area_sqft','propertylandusetypeid','total_finished_living_area_sqft','roomcnt','numberofstories' ] ,\n",
        "                  target = 'total_property_tax_2016')\n",
        "\n",
        "print(\"predicted output shape\",missing_values.shape)\n",
        "missing_values_boolflag = df_train['total_property_tax_2016'].isnull()\n",
        "df_train.loc[ missing_values_boolflag, 'total_property_tax_2016' ] = missing_values.round(2)\n",
        "print(df_train.total_property_tax_2016.isnull().sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlaxWegqz7I-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check missing values\n",
        "\n",
        "missing_df = df_train.isnull().sum(axis=0).reset_index()\n",
        "missing_df.columns = ['column_name', 'missing_count']\n",
        "missing_df = missing_df.loc[missing_df['missing_count']>0]\n",
        "missing_df = missing_df.sort_values(by='missing_count')\n",
        "print(missing_df)\n",
        "print(missing_df.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIl_nqKVz7NQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#both the columns above miss 92% of the data, there is no related varibale to impute it, hence dropping them at this point\n",
        "\n",
        "df_train = df_train.drop(['finished_living_area_entryfloor_sqft2','finished_living_area_entryfloor_sqft1'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQJd7rgKz7Qq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Identify numerical columns to produce a heatmap\n",
        "catcols = ['ac_id','buildingqualitytypeid','deck_flag','fips','pool_with_spa_tub_no','pool_with_spa_tub_yes','has_hottub_or_spa',\n",
        "           'just_hottub_or_spa','heating_system_id','propertylandusetypeid','basement_flag','fireplaceflag','taxdelinquencyflag']\n",
        "numcols = [x for x in df_train.columns if x not in catcols]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUN3a6uJz7Ut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2 variables are in object datatype, coverting into numeric\n",
        "df_train[['census_tractnumber','block_number']] = df_train[['census_tractnumber','block_number']].apply(pd.to_numeric)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGx77rRAz7ZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dropping categorical columns as xgboost feature selection cannot hadle it\n",
        "\n",
        "train_x = df_train.drop(catcols+['logerror'], axis=1)\n",
        "\n",
        "train_y=df_train['logerror']\n",
        "\n",
        "train_x = train_x.astype(float) \n",
        "train_y = train_y.astype(float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es_Ew2YJz7dT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.options.display.max_rows = 65\n",
        "\n",
        "dtype_df = train_x.dtypes.reset_index()\n",
        "dtype_df.columns = [\"Count\", \"Column Type\"]\n",
        "#dtype_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvWIhR38z7fW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.loc[df_train.has_hottub_or_spa==True,'has_hottub_or_spa']=\"Yes\"\n",
        "df_train.loc[df_train.has_hottub_or_spa==0,'has_hottub_or_spa']=\"No\"\n",
        "\n",
        "df_train.loc[df_train.just_hottub_or_spa==0,'just_hottub_or_spa']=\"No\"\n",
        "df_train.loc[df_train.just_hottub_or_spa==1,'just_hottub_or_spa']=\"Yes\"\n",
        "\n",
        "df_train.loc[df_train.deck_flag==0,'deck_flag']=\"No\"\n",
        "df_train.loc[df_train.deck_flag==1,'deck_flag']=\"Yes\"\n",
        "\n",
        "df_train.loc[df_train.basement_flag==0,'basement_flag']=\"No\"\n",
        "df_train.loc[df_train.basement_flag==1,'basement_flag']=\"Yes\"\n",
        "\n",
        "df_train.loc[df_train.fireplaceflag==False,'fireplaceflag']=\"No\"\n",
        "df_train.loc[df_train.fireplaceflag==True,'fireplaceflag']=\"Yes\"\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef9JjrmMz7jw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ac_id,heating_system_id,propertylandusetypeid\n",
        "dummieslist=['has_hottub_or_spa','just_hottub_or_spa',\n",
        "             'deck_flag','fips','basement_flag','fireplaceflag','taxdelinquencyflag']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z51Zrt2Uz7oD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train[dummieslist] = df_train[dummieslist].astype(object)\n",
        "dummies = pd.get_dummies(df_train[dummieslist], prefix= dummieslist)\n",
        "dummies.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHBi5Gg6z7tu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummies2=['pool_with_spa_tub_no','pool_with_spa_tub_yes']\n",
        "df_train[dummies2] = df_train[dummies2].astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oocTPKI9z7rk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import MySQLdb\n",
        "from sqlalchemy import create_engine\n",
        "engineString = 'mysql+mysqldb://root:MyNewPass@localhost/sakila'\n",
        "engine = create_engine(engineString)\n",
        "con=engine.connect()\n",
        "\n",
        "with engine.connect() as con, con.begin():\n",
        "    df_train.to_sql('df_train_f1', engine, chunksize=10000, index =False,if_exists ='replace')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj5ZLSPlz7XC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numcols2=['basementsqft','total_bath','bedroomcnt','total_finished_living_area_sqft','fireplace_count','garagecarcnt',\n",
        " 'garage_sqft','latitude','longitude','lot_area_sqft','poolcnt','pool_sqft','roomcnt','unitcnt','patio_sqft','storage_sqft',\n",
        " 'numberofstories','structure_tax','total_parcel_tax','land_tax','total_property_tax_2016','taxdelinquencyyear','transaction_month',\n",
        " 'census_tractnumber','block_number','age']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp53dotszhgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y=df_train['logerror']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0Uaei4rzhj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#buildingqualitytypeid ->has order\n",
        "le = LabelEncoder()\n",
        "df_train['buildingqualitytypeid']=le.fit_transform(df_train.buildingqualitytypeid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4-g-uvtzhds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df_train.ac_id.value_counts()\n",
        "#df_train.propertylandusetypeid.value_counts()\n",
        "#'buildingqualitytypeid','ac_id','heating_system_id','propertylandusetypeid'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzliXafdzhRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=pd.concat([dummies,df_train[dummies2],df_train[numcols2],df_train[['buildingqualitytypeid','ac_id','heating_system_id','propertylandusetypeid']]],axis=1)\n",
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBsZjyQd0W1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.10, random_state=3192)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihXFZWcn0W5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  top features\n",
        "import xgboost as xgb\n",
        "xgb_params = {\n",
        "    'eta': 0.05,\n",
        "    'max_depth': 8,\n",
        "    'subsample': 0.7,\n",
        "    'colsample_bytree': 0.7,\n",
        "    'objective': 'reg:linear',\n",
        "    'silent': 1,\n",
        "    'seed' : 0\n",
        "}\n",
        "dtrain = xgb.DMatrix(X_train, Y_train, feature_names=X_train.columns.values)\n",
        "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=50)\n",
        "# plot the important features #\n",
        "fig, ax = plt.subplots(figsize=(12,18))\n",
        "#max_num_features=50, error for no reason \n",
        "xgb.plot_importance(model, height=0.8, ax=ax)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQEEzNkX0W9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#top features\n",
        "xgboost_selection=['total_finished_living_area_sqft','latitude','structure_tax','total_property_tax_2016',\n",
        "'total_parcel_tax','land_tax','longitude','lot_area_sqft','census_tractnumber','age','total_bath','bedroomcnt',\n",
        "'block_number','transaction_month','roomcnt','taxdelinquencyyear','unitcnt','taxdelinquencyflag_No',\n",
        "'fips_LA','garage_sqft','pool_with_spa_tub_no','has_hottub_or_spa_No','garagecarcnt','deck_flag_No',\n",
        "'poolcnt','pool_sqft'\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr_6EO4G0XEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# feature selection\n",
        "#c_id,heating_system_id,propertylandusetypeid\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "reg = ExtraTreesRegressor(n_estimators=500, max_depth=8, max_features='sqrt',\n",
        "                          min_samples_split=100 ,min_samples_leaf=10, bootstrap=True,n_jobs=-1, random_state=3192)\n",
        "reg = reg.fit(X_train, Y_train)\n",
        "#print(\"importance\",reg.feature_importances_) \n",
        "model = SelectFromModel(reg, prefit=True)\n",
        "X_new = model.transform(X_train)\n",
        "print(X_train.shape)\n",
        "print(X_new.shape)  \n",
        "\n",
        "feat_names = X.columns.values\n",
        "importances = reg.feature_importances_\n",
        "std = np.std([tree.feature_importances_ for tree in reg.estimators_], axis=0)\n",
        "indices = np.argsort(importances)[::-1][:26]\n",
        "plt.figure(figsize=(12,12))\n",
        "plt.title(\"Feature importances\")\n",
        "plt.bar(range(len(indices)), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\n",
        "plt.xticks(range(len(indices)), feat_names[indices], rotation='vertical')\n",
        "plt.xlim([-1, len(indices)])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4FCNOG70XIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tree_selection=[\n",
        "    'total_finished_living_area_sqft','structure_tax','total_property_tax_2016','total_bath','total_parcel_tax',\n",
        "    'age','latitude','census_tractnumber','bedroomcnt','longitude','land_tax','propertylandusetypeid','block_number',\n",
        "    'buildingqualitytypeid','numberofstories','heating_system_id','unitcnt','transaction_month','lot_area_sqft','roomcnt',\n",
        "    'garage_sqft','garagecarcnt','pool_with_spa_tub_no','poolcnt','fips_LA','taxdelinquencyyear','patio_sqft',\n",
        "    'taxdelinquencyflag_No','taxdelinquencyflag_Yes'\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmIS1WAS0XMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import Ridge,Lasso\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score,mean_absolute_error,make_scorer\n",
        "\n",
        "#model=Lasso(alpha=0.2, fit_intercept=True, normalize=True, precompute=False, copy_X=True,\n",
        " #                                max_iter=1000, \n",
        "  #                               tol=0.0001, warm_start=False, positive=False, random_state=3192, selection='cyclic')\n",
        "\n",
        "#Ridge(random_state=3192,solver='auto',fit_intercept=True,normalize=True,alpha=0.1)\n",
        "#LinearRegression(n_jobs=-1,fit_intercept=True, normalize=True, copy_X=True)\n",
        "\n",
        "\n",
        "rfecv = RFECV(estimator=LinearRegression(n_jobs=-1,fit_intercept=True, normalize=True, copy_X=True), step=2, cv=KFold(4),scoring='neg_mean_absolute_error')\n",
        "rfecv.fit(X_train, Y_train)\n",
        "\n",
        "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
        "\n",
        "# Plot number of features VS. cross-validation scores\n",
        "plt.figure()\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "\n",
        "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
        "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIw8O00U0XPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rfe_selection = [i for indx,i in enumerate(X.columns) if rfecv.support_[indx] == True]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHA0x5_80XWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Linear regression with rfe_selection selection\n",
        "#rfe_selection, tree_selection, xgboost_selection\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score,mean_absolute_error,make_scorer,mean_squared_error\n",
        "\n",
        "# just to check whether normalized /not normalized data gives better results\n",
        "parameters = {'fit_intercept':[True], 'normalize':[True,False], 'copy_X':[True]}\n",
        "scoring = {'MAE':'neg_mean_absolute_error','MSE': make_scorer(mean_squared_error,greater_is_better=False)}\n",
        "\n",
        "grid1 = GridSearchCV(LinearRegression(n_jobs=-1),param_grid=parameters, scoring=scoring,cv=5,refit='MAE',\n",
        "                    return_train_score=True,\n",
        "                    verbose=0,n_jobs=-1,pre_dispatch='n_jobs')\n",
        "\n",
        "grid1.fit(X_train[rfe_selection], Y_train)\n",
        "#print(\"5. grid best_score_\",abs(grid.best_score_))\n",
        "Y_pred = grid1.predict(X_test[rfe_selection])\n",
        "print(\"MAE on test data\",mean_absolute_error(Y_test,Y_pred))\n",
        "print(\"MSE on test data\",mean_squared_error(Y_test,Y_pred))\n",
        "print(\"R Squared data \",r2_score(Y_test,Y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekn4pBs60XcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pca selection\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import scale\n",
        "%matplotlib inline\n",
        "scaled_x = scale(X)\n",
        "pca = PCA(n_components=None, copy=True, whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto', random_state=None)\n",
        "pca.fit(scaled_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFuT-wUN0XfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The amount of variance that each PC explains\n",
        "var= pca.explained_variance_ratio_\n",
        "#Cumulative Variance explains\n",
        "var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
        "print(var1)\n",
        "plt.plot(var1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPN4OBUe0XlD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Looking at above plot I'm taking 28 variables\n",
        "\n",
        "pca = PCA(n_components=28, copy=True, whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto', random_state=None)\n",
        "pca.fit(scaled_x)\n",
        "\n",
        "pca1=pca.fit_transform(scaled_x)\n",
        "\n",
        "pca = PCA(n_components=28, copy=True, whiten=True, svd_solver='auto', tol=0.0, iterated_power='auto', random_state=None)\n",
        "pca.fit(scaled_x)\n",
        "pca2=pca.fit_transform(scaled_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE4ednPC0XjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pcaX_train, pcaX_test, pcaY_train, pcaY_test = train_test_split(pca1, Y, test_size=0.10, random_state=3192)\n",
        "pca2X_train, pca2X_test, pca2Y_train, pca2Y_test = train_test_split(pca2, Y, test_size=0.10, random_state=3192)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erYMXvTG0XaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error,make_scorer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# just to check whether normalized /not normalized data gives better results\n",
        "\n",
        " # 0.005 for 1200 trees.\n",
        "param_grid={'n_estimators':[1200],'max_features':[22]}\n",
        "\n",
        "              \n",
        "grid13 = GridSearchCV(GradientBoostingRegressor(subsample=0.8,min_samples_leaf=50,min_samples_split=50,max_depth=9,loss='ls',criterion='friedman_mse',learning_rate=0.005,random_state=3192),\n",
        "                     param_grid=param_grid, cv=5,refit='MAE',\n",
        "                    return_train_score=True,\n",
        "                    verbose=2,n_jobs=-1,pre_dispatch='n_jobs')\n",
        "\n",
        "grid13.fit(pcaX_train, pcaY_train)\n",
        "print(\"5. grid best_score_\",abs(grid13.best_score_))\n",
        "print(\"best params\",grid13.best_params_)\n",
        "print(\"best score\",grid13.best_score_)\n",
        "Y_pred = grid13.predict(pcaX_test)\n",
        "print(\"MAE on test data\",mean_absolute_error(pcaY_test,Y_pred))\n",
        "print(\"MSE on test data\",mean_squared_error(pcaY_test,Y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgtbLCcR0XUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjdSCEFP0XCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}